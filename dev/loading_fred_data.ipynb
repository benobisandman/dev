{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime , timedelta\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "fred_key = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_vintage_fed_0(\n",
    "    series_name:str,\n",
    "    output_type:int=4,\n",
    "    api_key=fred_key\n",
    ")-> pd.DataFrame :\n",
    "    \"\"\"A function specific to the fred api, that requests all the data vintage from 2010, with all the revision\n",
    "    Args:\n",
    "        series_name (str): series id from FRED, ex INDPRO for industrial production\n",
    "        output_type (int, optional): _description_. Defaults to 4: first vintage, for all vintage use 2, last vintage 1\n",
    "        api_key (_type_, optional): _description_. Defaults to fred_key.\n",
    "\n",
    "    Returns:\n",
    "        a df with as an index the date that the data relates to (for instance 2022-10-31 for October 2022 Industrial Production)\n",
    "        a value column and a publication date column, to get all the data available at one date, you just use df.loc[df['publication_date']=='date']\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    "    fred_url = f\"{base_url}series_id={series_name}&api_key={api_key}&realtime_start=1986-01-01&file_type=json&output_type={output_type}\"\n",
    "\n",
    "\n",
    "    response = requests.get(url=fred_url)\n",
    "    try:\n",
    "        assert response.status_code == requests.codes.ok\n",
    "\n",
    "        json_data = json.loads(response.content)[\"observations\"]\n",
    "\n",
    "        df = pd.DataFrame.from_records(json_data)\n",
    "\n",
    "    except AssertionError:\n",
    "        print(\"Bad URL!\")\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    df=df.set_index(\"date\")\n",
    "    \n",
    "    if output_type==4:\n",
    "        df['realtime_start']=pd.to_datetime(df['realtime_start'])\n",
    "        df['value']=df['value'].replace('.',np.nan).astype(float)\n",
    "        return df[['value','realtime_start']].rename(columns={'value':series_name,'realtime_start':'publication_date'})\n",
    "    elif output_type==1:\n",
    "        return df['value'].rename(series_name)\n",
    "        #df.index = df.index + pd.offsets.MonthEnd(0)\n",
    "    df=(\n",
    "        df\n",
    "        .dropna(axis=0,how='all')\n",
    "        .replace('.',value=np.nan)\n",
    "        .astype('float')\n",
    "    )\n",
    "\n",
    "    df.columns = pd.to_datetime(df.columns.str.replace(f'{series_name}_', ''))\n",
    "    df=(\n",
    "        df\n",
    "        #.loc['2010':]\n",
    "        .sort_index(axis=1,ascending=True)\n",
    "        .melt(ignore_index=False)\n",
    "        .rename(columns={'variable':'publication_date','value':series_name})\n",
    "\n",
    "        .dropna()\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_vintage_fed(\n",
    "    series_name:str,\n",
    "    api_key:str = fred_key,\n",
    "    output_type:int=4,\n",
    "    base_url:str = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    ")-> pd.DataFrame :\n",
    "    \"\"\"A function specific to the fred api, that requests all the data vintage from 2010, with all the revision\n",
    "    Args:\n",
    "        series_name (str): series id from FRED, ex INDPRO for industrial production\n",
    "        output_type (int, optional): _description_. Defaults to 4: first vintage, for all vintage use 2, last vintage 1\n",
    "        api_key (str, optional): Personal API key. Defaults to fred_key\n",
    "        base_url(str) : Defaults to https://api.stlouisfed.org/fred/series/observations?\n",
    "\n",
    "    Returns:\n",
    "        a df with as an index the date that the data relates to (for instance 2022-10-31 for October 2022 Industrial Production)\n",
    "        a value column and a publication date column, to get all the data available at one date, you just use df.loc[df['publication_date']=='date']\n",
    "    \"\"\"\n",
    "    #base_url = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    "    fred_url = f\"{base_url}series_id={series_name}&api_key={api_key}&realtime_start=1986-01-01&file_type=json&output_type={output_type}\"\n",
    "\n",
    "\n",
    "    response = requests.get(url=fred_url)\n",
    "    try:\n",
    "        assert response.status_code == requests.codes.ok\n",
    "\n",
    "        json_data = json.loads(response.content)[\"observations\"]\n",
    "\n",
    "        df = pd.DataFrame.from_records(json_data)\n",
    "\n",
    "    except AssertionError:\n",
    "        print(\"Bad URL!\")\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    \n",
    "    df=df.set_index(\"date\")\n",
    "    \n",
    "    if output_type==4:\n",
    "        df['realtime_start']=pd.to_datetime(df['realtime_start'])\n",
    "        df['value']=df['value'].replace('.',np.nan).astype(float)\n",
    "        return df[['value','realtime_start']].rename(columns={'value':series_name,'realtime_start':'publication_date'})\n",
    "    elif output_type==1:\n",
    "        return df['value'].rename(series_name)\n",
    "        #df.index = df.index + pd.offsets.MonthEnd(0)\n",
    "    df=(\n",
    "        df\n",
    "        .dropna(axis=0,how='all')\n",
    "        .replace('.',value=np.nan)\n",
    "        .astype('float')\n",
    "    )\n",
    "\n",
    "    df.columns = pd.to_datetime(df.columns.str.replace(f'{series_name}_', ''))\n",
    "    df=(\n",
    "        df\n",
    "        #.loc['2010':]\n",
    "        .sort_index(axis=1,ascending=True)\n",
    "        .melt(ignore_index=False)\n",
    "        .rename(columns={'variable':'publication_date','value':series_name})\n",
    "\n",
    "        .dropna()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select a vintage from the all vintage series: i_vintage=0 means last, 1 means the one before etc\n",
    "\n",
    "def select_one_vintage_0(df: pd.DataFrame,series_id :str,i_vintage:int=0)-> pd.DataFrame :\n",
    "    #vintage_date=df.publication_date.drop_duplicates().nlargest(n=i_vintage+1,keep='last')[i_vintage]\n",
    "    vintage_date=df.publication_date.drop_duplicates().nlargest(n=i_vintage+1,keep='last').iloc[i_vintage]\n",
    " \n",
    "    df=(\n",
    "        df\n",
    "        .loc[df.publication_date==vintage_date]\n",
    "        )\n",
    "\n",
    "    df=(\n",
    "        df\n",
    "        .loc[~df.index.duplicated(keep='first')]\n",
    "        .loc[:,['publication_date',series_id]]\n",
    "    )\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def select_one_vintage(df: pd.DataFrame, series_id:str,i_vintage:int=0)-> pd.DataFrame:\n",
    "#     \"\"\"\"\"\"\n",
    "#     vintage_date=df.publication_date.drop_duplicates().nlargest(n=i_vintage+1,keep='last').iloc[i_vintage]\n",
    "\n",
    "#     df = df.loc[df.publication_date == vintage_date]\n",
    "\n",
    "#     df = df.loc[~df.index.duplicated(keep='first'), ['publication_date', series_id]]    \n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading claims data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get all the vintages : output_type=2 in get_all_data_vintage_fed\n",
    "- To get only the first vintage : output_type=4 in get_all_data_vintage_fed\n",
    "- To get only the last vintage: do get_all_data_vintage_fed(...,output_type=2) and then select_one_vintage(....,i_vintage=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common series name in claims: <br>\n",
    "- Initial Claims SA : ICSA\n",
    "- Initial Claims NSA : ICNSA\n",
    "- Continuous Claims SA : CCSA\n",
    "- Continuous Claims NSA : CCNSA <br>\n",
    "For state claims, add the two letter state code before the series : TXICSA, CACCNSA, NYCCSA etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\ I haven't found a good way to request multiple series at the same type, you have to do one request per series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_name='CCSA'\n",
    "\n",
    "df_first_nsa_0 = get_all_data_vintage_fed_0(series_name,output_type=4)[series_name]\n",
    "df_all_vintage_0 = get_all_data_vintage_fed_0(series_name,output_type=2)\n",
    "\n",
    "df_first_nsa=get_all_data_vintage_fed(series_name,output_type=4)[series_name]\n",
    "df_all_vintage=get_all_data_vintage_fed(series_name,output_type=2)\n",
    "\n",
    "print(df_first_nsa_0.equals(df_first_nsa))\n",
    "print(df_all_vintage_0.equals(df_all_vintage))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_last_nsa=select_one_vintage(df_all_vintage,series_name,0)[series_name]\n",
    "\n",
    "df_last_nsa_2=select_one_vintage_2(df_all_vintage,series_name,0)[series_name]\n",
    "\n",
    "df_last_nsa.equals(df_last_nsa_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducing the pseudo real time claims : first vintage when available (after 2009), and last vintage before that\n",
    "begin_live=df_first_nsa.first_valid_index()\n",
    "df_real_time=pd.concat([df_last_nsa.loc[:begin_live].iloc[:-1],df_first_nsa],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the actual publication date, request the first vintage series, there is a publication_date columns\n",
    "df_with_publication_date=get_all_data_vintage_fed(series_name,output_type=4)\n",
    "print(df_with_publication_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_nsa.info()\n",
    "df_first_nsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_vintage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_vintage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-FM2PHDVP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
